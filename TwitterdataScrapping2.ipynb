{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqaOr7ruoadKQvHkd/EYUx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kidd89/TwitterScrapping/blob/main/TwitterdataScrapping2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_svD1u80ayh",
        "outputId": "bb3122c5-c955-4b7b-9ba3-b287dd889114"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Collecting packaging<24,>=16.8 (from streamlit)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, packaging, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 packaging-23.2 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.32.2 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJs2_sK00jRu",
        "outputId": "183f2fca-f680-4de5-831a-da57a74c605a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting twint\n",
            "  Downloading twint-2.1.20.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from twint) (3.9.3)\n",
            "Collecting aiodns (from twint)\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from twint) (4.12.3)\n",
            "Collecting cchardet (from twint)\n",
            "  Downloading cchardet-2.1.7.tar.gz (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elasticsearch (from twint)\n",
            "  Downloading elasticsearch-8.13.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.0/451.0 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pysocks in /usr/local/lib/python3.10/dist-packages (from twint) (1.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from twint) (2.0.3)\n",
            "Collecting aiohttp_socks (from twint)\n",
            "  Downloading aiohttp_socks-0.8.4-py3-none-any.whl (9.6 kB)\n",
            "Collecting schedule (from twint)\n",
            "  Downloading schedule-1.2.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (from twint) (2.3.0)\n",
            "Collecting fake-useragent (from twint)\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Collecting googletransx (from twint)\n",
            "  Downloading googletransx-2.4.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycares>=4.0.0 (from aiodns->twint)\n",
            "  Downloading pycares-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->twint) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->twint) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->twint) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->twint) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->twint) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->twint) (4.0.3)\n",
            "Collecting python-socks[asyncio]<3.0.0,>=2.4.3 (from aiohttp_socks->twint)\n",
            "  Downloading python_socks-2.4.4-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->twint) (2.5)\n",
            "Collecting elastic-transport<9,>=8.13 (from elasticsearch->twint)\n",
            "  Downloading elastic_transport-8.13.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy->twint) (2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletransx->twint) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->twint) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->twint) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->twint) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->twint) (1.25.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch->twint) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch->twint) (2024.2.2)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from pycares>=4.0.0->aiodns->twint) (1.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->twint) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->twint) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletransx->twint) (3.3.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->twint) (2.22)\n",
            "Building wheels for collected packages: twint, cchardet, googletransx\n",
            "  Building wheel for twint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twint: filename=twint-2.1.20-py3-none-any.whl size=33912 sha256=d4cabfe793dc6cf64950a4f6b95c551ce3a5b72bc7fa9f778fb2f0b017c82107\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/d2/f5/7a71ea8b6788b85fac82abf4ef84dac03562571f695c3b8f77\n",
            "  Building wheel for cchardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=289390 sha256=6db22a2e4d81bb47927197085b001a714e94c3a1b3567829bbc1c7fca7795fd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\n",
            "  Building wheel for googletransx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletransx: filename=googletransx-2.4.2-py3-none-any.whl size=15953 sha256=4eef13a59424d7f650f3767b80316a142924671e9b2fe7bdd0af19e0b068356a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/79/4f/43718126b3548eda695b4c2fa4cd82667b2d62018a98dc6767\n",
            "Successfully built twint cchardet googletransx\n",
            "Installing collected packages: python-socks, fake-useragent, cchardet, schedule, elastic-transport, pycares, googletransx, elasticsearch, aiohttp_socks, aiodns, twint\n",
            "Successfully installed aiodns-3.2.0 aiohttp_socks-0.8.4 cchardet-2.1.7 elastic-transport-8.13.0 elasticsearch-8.13.0 fake-useragent-1.5.1 googletransx-2.4.2 pycares-4.4.0 python-socks-2.4.4 schedule-1.2.1 twint-2.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install botocore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aMXFeWq0oMT",
        "outputId": "8714ce28-da39-463a-acd8-795e2593262f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting botocore\n",
            "  Downloading botocore-1.34.77-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from botocore)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore\n",
            "Successfully installed botocore-1.34.77 jmespath-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbLY46Ut3FLQ",
        "outputId": "c51dd587-d76f-43f7-81de-69b58a1b9bc0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting functions\n",
            "  Downloading functions-0.7.0.tar.gz (2.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: functions\n",
            "  Building wheel for functions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for functions: filename=functions-0.7.0-py3-none-any.whl size=3036 sha256=c212be841a6dc003e89107ab2c09b68ba8a25dfc95e2ade78c7e37b3ec3949ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/90/bc/01eb2f163bcfa49c7ad5072fbe9d243038368b9001ec26a9da\n",
            "Successfully built functions\n",
            "Installing collected packages: functions\n",
            "Successfully installed functions-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install snscrape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QMgFpkR5FGc",
        "outputId": "fd2b58b1-d22d-4b39-da57-e7d9be7c9ce9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snscrape\n",
            "  Downloading snscrape-0.7.0.20230622-py3-none-any.whl (74 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from snscrape) (2.31.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from snscrape) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from snscrape) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from snscrape) (3.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->snscrape) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.7.0.20230622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import datetime\n",
        "\n",
        "tweets_df = pd.DataFrame()\n",
        "st.write(\"# Twitter data scraping\")\n",
        "option = st.selectbox('How would you like the data to be searched?',('Keyword', 'Hashtag'))\n",
        "word = st.text_input('Please enter a '+option, 'LIC Policy')\n",
        "start = st.date_input(\"Select the start date\", datetime.date(2022, 1, 1),key='d1')\n",
        "end = st.date_input(\"Select the end date\", datetime.date(2023, 1, 1),key='d2')\n",
        "tweet_c = st.slider('How many tweets to scrape', 0, 1000, 5)\n",
        "tweets_list = []\n",
        "\n",
        "# SCRAPE DATA USING TwitterSearchScraper\n",
        "if word:\n",
        "    try:\n",
        "        if option=='Keyword':\n",
        "            for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{word} lang:en since:{start} until:{end}').get_items()):\n",
        "                if i>tweet_c-1:\n",
        "                    break\n",
        "                tweets_list.append([ tweet.content, tweet.user.username, tweet.replyCount, tweet.retweetCount,tweet.likeCount ])\n",
        "            tweets_df = pd.DataFrame(tweets_list, columns=['Content', 'Username', 'ReplyCount', 'RetweetCount', 'LikeCount'])\n",
        "        else:\n",
        "            for i,tweet in enumerate(sntwitter.TwitterHashtagScraper(f'{word} lang:en since:{start} until:{end}').get_items()):\n",
        "                if i>tweet_c-1:\n",
        "                    break\n",
        "                tweets_list.append([ tweet.content, tweet.user.username, tweet.replyCount, tweet.retweetCount,tweet.likeCount ])\n",
        "            tweets_df = pd.DataFrame(tweets_list, columns=['Content', 'Username', 'ReplyCount', 'RetweetCount', 'LikeCount'])\n",
        "    except Exception as e:\n",
        "        st.error(f\"Too many requests, TwitterRateLimit exceeded, please try again after few hours\")\n",
        "        st.stop()\n",
        "\n",
        "else:\n",
        "    st.warning(option,' cant be empty', icon=\"⚠️\")\n",
        "\n",
        "#SIDEBAR\n",
        "with st.sidebar:\n",
        "    st.info('DETAILS', icon=\"ℹ️\")\n",
        "    if option=='Keyword':\n",
        "        st.info('Keyword is '+word)\n",
        "    else:\n",
        "        st.info('Hashtag is '+word)\n",
        "    st.info('Starting Date is '+str(start))\n",
        "    st.info('End Date is '+str(end))\n",
        "    st.info(\"Number of Tweets \"+str(tweet_c))\n",
        "    st.info(\"Total Tweets Scraped \"+str(len(tweets_df)))\n",
        "    x=st.button('Show Tweets',key=1)\n",
        "\n",
        "# DOWNLOAD AS CSV\n",
        "@st.cache # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
        "def convert_df(df):\n",
        "    return df.to_csv().encode('utf-8')\n",
        "\n",
        "if not tweets_df.empty:\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        csv = convert_df(tweets_df) # CSV\n",
        "        c=st.download_button(label=\"Download data as CSV\",data=csv,file_name='Twitter_data.csv',mime='text/csv',)\n",
        "    with col2:    # JSON\n",
        "        json_string = tweets_df.to_json(orient ='records')\n",
        "        j=st.download_button(label=\"Download data as JSON\",file_name=\"Twitter_data.json\",mime=\"application/json\",data=json_string,)\n",
        "\n",
        "    with col3: # SHOW\n",
        "        y=st.button('Show Tweets',key=2)\n",
        "\n",
        "if c:\n",
        "    st.success(\"The Scraped Data is Downloaded as .CSV file:\",icon=\"✅\")\n",
        "if j:\n",
        "    st.success(\"The Scraped Data is Downloaded as .JSON file\",icon=\"✅\")\n",
        "if x: # DISPLAY\n",
        "    st.success(\"The Scraped Data is:\",icon=\"✅\")\n",
        "    st.write(tweets_df)\n",
        "if y: # DISPLAY\n",
        "    st.balloons()\n",
        "    st.success(\"Tweets Scraped Successfully:\",icon=\"✅\")\n",
        "    st.write(tweets_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "I1sBO5rF5C-S",
        "outputId": "f5c7c94a-aa6f-41b9-baef-512a8357bbae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-04 16:23:01.587 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "ERROR:snscrape.base:Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "CRITICAL:snscrape.base:4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'c' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f10736dfee97>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbutton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Show Tweets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The Scraped Data is Downloaded as .CSV file:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0micon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"✅\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk8_09vOzlSA",
        "outputId": "73aed96d-2156-47aa-c6f8-f3d1130a5360"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.227.21.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMEuihtizpUg",
        "outputId": "abdcc4d0-5269-4022-9832-ff5207b38056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.21.30:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.814s\n",
            "your url is: https://chubby-moments-open.loca.lt\n",
            "Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n",
            "Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n",
            "Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n",
            "Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n",
            "Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        }
      ]
    }
  ]
}